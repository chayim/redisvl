{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizers\n",
    "\n",
    "In this notebook, we will show how to use RedisVL to create embeddings using the built-in text embedding vectorizers. Today RedisVL supports:\n",
    "1. OpenAI\n",
    "2. HuggingFace\n",
    "\n",
    "Before running this notebook, be sure to\n",
    "1. Have installed ``redisvl`` and have that environment active for this notebook.\n",
    "2. Have a running Redis instance with RediSearch > 2.4 running.\n",
    "\n",
    "For example, you can run Redis locally with Docker:\n",
    "\n",
    "```bash\n",
    "docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
    "```\n",
    "\n",
    "which will run Redis on port 6379 and RedisInsight at http://localhost:8001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Text Embeddings\n",
    "\n",
    "This example will show how to create an embedding from 3 simple sentences with a number of different text vectorizers in RedisVL.\n",
    "\n",
    "- \"That is a happy dog\"\n",
    "- \"That is a happy person\"\n",
    "- \"Today is a nice day\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "The ``OpenAITextVectorizer`` makes it simple to use RedisVL with the embeddings models at OpenAI. For this you will need to install ``openai``. \n",
    "\n",
    "```bash\n",
    "pip install openai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# setup the API Key\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dimensions:  1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.001046799123287201,\n",
       " -0.0031105349771678448,\n",
       " 0.0024228920228779316,\n",
       " -0.004480978474020958,\n",
       " -0.010343699716031551,\n",
       " 0.012758520431816578,\n",
       " -0.00535263866186142,\n",
       " -0.003002384677529335,\n",
       " -0.007115328684449196,\n",
       " -0.03378167003393173]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redisvl.vectorize.text import OpenAITextVectorizer\n",
    "\n",
    "oai = OpenAITextVectorizer(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_config={\"api_key\": api_key},\n",
    ")\n",
    "\n",
    "test = oai.embed(\"This is a test sentence.\")\n",
    "print(\"Vector dimensions: \", len(test))\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.017399806529283524,\n",
       " -2.3427608653037169e-07,\n",
       " 0.0014656063867732882,\n",
       " -0.02562308870255947,\n",
       " -0.019890939816832542,\n",
       " 0.016027139499783516,\n",
       " -0.0036763285752385855,\n",
       " 0.0008253469131886959,\n",
       " 0.006609130185097456,\n",
       " -0.025165533646941185]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create many embeddings at once\n",
    "sentences = [\n",
    "    \"That is a happy dog\",\n",
    "    \"That is a happy person\",\n",
    "    \"Today is a sunny day\"\n",
    "]\n",
    "\n",
    "embeddings = oai.embed_many(sentences)\n",
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 3\n"
     ]
    }
   ],
   "source": [
    "# openai also supports asyncronous requests, which we can use to speed up the vectorization process.\n",
    "embeddings = await oai.aembed_many(sentences)\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface\n",
    "\n",
    "Huggingface is a popular NLP library that has a number of pre-trained models. RedisVL supports using Huggingface to create embeddings from these models. To use Huggingface, you will need to install the ``sentence-transformers`` library.\n",
    "\n",
    "```bash\n",
    "pip install sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam.partee/.virtualenvs/rvl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00037813105154782534,\n",
       " -0.05080341547727585,\n",
       " -0.03514720872044563,\n",
       " -0.023251093924045563,\n",
       " -0.04415826499462128,\n",
       " 0.020487893372774124,\n",
       " 0.0014619074063375592,\n",
       " 0.03126181662082672,\n",
       " 0.056051574647426605,\n",
       " 0.0188154224306345]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from redisvl.vectorize.text import HFTextVectorizer\n",
    "\n",
    "\n",
    "# create a provider\n",
    "hf = HFTextVectorizer(model=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# embed a sentence\n",
    "test = hf.embed(\"This is a test sentence.\")\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create many embeddings at once\n",
    "embeddings = hf.embed_many(sentences, as_buffer=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with Provider Embeddings\n",
    "\n",
    "Now that we've created our embeddings, we can use them to search for similar sentences. We will use the same 3 sentences from above and search for similar sentences.\n",
    "\n",
    "First, we need to create the schema for our index.\n",
    "\n",
    "Here's what the schema for the example looks like in yaml for the HuggingFace vectorizer:\n",
    "\n",
    "```yaml\n",
    "index:\n",
    "    name: providers\n",
    "    prefix: rvl\n",
    "\n",
    "fields:\n",
    "    text:\n",
    "        - name: sentence\n",
    "    vector:\n",
    "        - name: embedding\n",
    "          dims: 768\n",
    "          algorithm: flat\n",
    "          distance_metric: cosine\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.index import SearchIndex\n",
    "\n",
    "# construct a search index from the schema\n",
    "index = SearchIndex.from_yaml(\"./schema.yaml\")\n",
    "\n",
    "# connect to local redis instance\n",
    "index.connect(\"redis://localhost:6379\")\n",
    "\n",
    "# create the index (no data yet)\n",
    "index.create(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m20:13:35\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Indices:\n",
      "\u001b[32m20:13:35\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   1. providers\n"
     ]
    }
   ],
   "source": [
    "# use the CLI to see the created index\n",
    "!rvl index listall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expects an iterable of dictionaries where\n",
    "# the vector is stored as a bytes buffer\n",
    "\n",
    "data = [{\"text\": t,\n",
    "         \"embedding\": v}\n",
    "        for t, v in zip(sentences, embeddings)]\n",
    "\n",
    "index.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is a happy dog\n",
      "0.160862445831\n",
      "That is a happy person\n",
      "0.273598074913\n",
      "Today is a sunny day\n",
      "0.744559526443\n"
     ]
    }
   ],
   "source": [
    "from redisvl.query import VectorQuery\n",
    "\n",
    "# use the HuggingFace vectorizer again to create a query embedding\n",
    "query_embedding = hf.embed(\"That is a happy cat\")\n",
    "\n",
    "query = VectorQuery(\n",
    "    vector=query_embedding,\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"text\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "results = index.search(query.query, query_params=query.params)\n",
    "for doc in results.docs:\n",
    "    print(doc.text)\n",
    "    print(doc.vector_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('redisvl2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b1e6e9c2967143209c2f955cb869d1d3234f92dc4787f49f155f3abbdfb1316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
